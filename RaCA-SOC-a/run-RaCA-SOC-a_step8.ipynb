{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0737caa3-6b11-47a4-b6b8-f5a4b3c31d57",
   "metadata": {},
   "source": [
    "# Step 8: Attempt to modify potentially problematic spectra through fit to data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6776db-332a-493b-8554-d98c356b3535",
   "metadata": {},
   "source": [
    "Since biases are large, and some of the spectra may be problematic for pure endmembers, let us now permit modifications to those spectra. Vary F for some of the endmembers which are predicted with high abundances far away from their expected global average values. \n",
    "\n",
    "The loss function to be minimized should be the prediction error on a minibatch of RaCA spectra.\n",
    "\n",
    "Can also try 1/R^2 - 1, where R^2 is the coefficient of regression for a plot of predicted vs. actual carbon content on a large minibatch of RaCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6869d9-fd5c-4da3-a92d-1bca81074501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import torch\n",
    "import torch .nn as nn\n",
    "import torch .optim as optim\n",
    "\n",
    "import json\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e73bdb-f217-4b5f-a662-480c8d692861",
   "metadata": {},
   "source": [
    "### Load RaCA data and post-process spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c004db5f-7041-453e-9598-c1123c86552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"../data/RaCA-spectra-raw.txt\",\n",
    "                 delimiter=\",\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f237c98c-ad68-4b10-bd2a-3ee20d2a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0,2152:]\n",
    "sample_top   = data[1:,2153].astype('float32')\n",
    "sample_bot   = data[1:,2154].astype('float32')\n",
    "sample_txtr  = data[1:,2156]\n",
    "sample_bd    = data[1:,2158].astype('float32')\n",
    "sample_bdsd  = data[1:,2159].astype('float32')\n",
    "sample_soc   = data[1:,2162].astype('float32')\n",
    "sample_socsd = data[1:,2163].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad22ff70-5cb5-4202-a589-b5fa8b73976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataI = data[1:,1:2152].astype('float32')\n",
    "XF = np.array([x for x in range(350,2501)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabfefd6-cc63-43d0-8f6e-a4bc5b15158c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039e09bc176242c0b1410b8aaafd73cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def postProcessSpectrum(xin,xout,refin) :\n",
    "    return np.interp(xout, xin, refin)\n",
    "\n",
    "for iSpec in tqdm(range(dataI.shape[0])) :\n",
    "            \n",
    "    wavelengths = [x for x in range(350,2501)]\n",
    "    reflectance = dataI[iSpec,:]\n",
    "    \n",
    "    newwave = np.array([wavelengths[i] for i in range(len(wavelengths)) if reflectance[i] is not None and reflectance[i] > 0.0 and reflectance[i] <= 1.0])\n",
    "    newref  = np.array([reflectance[i] for i in range(len(reflectance)) if reflectance[i] is not None and reflectance[i] > 0.0 and reflectance[i] <= 1.0])\n",
    "    \n",
    "    dataI[iSpec,:] = postProcessSpectrum(newwave,XF,newref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b34b6-09e9-4fcf-94a7-e6e4a0a627b2",
   "metadata": {},
   "source": [
    "### Define basic model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4d0825-37af-4663-b964-3ec928b6cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def A(ms,rhorads) :\n",
    "    tA = ms / rhorads\n",
    "    return (tA.T / np.sum(tA)).T\n",
    "\n",
    "def torchA(ms,rhorads) :\n",
    "    tA = ms / rhorads\n",
    "    return (tA.t() / torch.sum(tA)).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485fa88-7945-4831-880e-71545a9dd305",
   "metadata": {},
   "source": [
    "### Define models: Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc56561-a4ec-407f-a019-ae3d24b37722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMixingEncoder(nn.Module):\n",
    "    def __init__(self, M, K, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(M),\n",
    "            nn.Linear(M, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Collection of hidden layers\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Convert to vector of mass abundances.\n",
    "            nn.Linear(hidden_size, K), \n",
    "            \n",
    "            # No subsequent BatchNorm on last layer.\n",
    "            \n",
    "            # Use leaky ReLU: has gradient !=0 at large negative values\n",
    "            # so that very small abundances (large neg. values at this layer)\n",
    "            # sit in a region of nonvanishing gradient\n",
    "            nn.LeakyReLU()            \n",
    "        )\n",
    "        \n",
    "        # Softmax to ensure abundances add up to 1\n",
    "        self.smax = nn.Softmax() \n",
    "        \n",
    "    def forward(self, y):\n",
    "        y_mlp = self.mlp(y);\n",
    "        ms = self.smax(y_mlp);\n",
    "        return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb4bc5b-28b1-4ac8-ab5c-16c5b6c5ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMixingDecoder(nn.Module):\n",
    "    def __init__(self, seedFs, seedMs, rhorad):\n",
    "        super().__init__()\n",
    "        \n",
    "        # fixed quantities\n",
    "        self.rhorad = rhorad[:-1]\n",
    "        \n",
    "        # model parameters\n",
    "        self.Fs     = nn.Parameter(seedFs)\n",
    "        self.rrsoc  = nn.Parameter(rhorad[-1])\n",
    "        \n",
    "    def forward(self, Ms):\n",
    "        rrFull = torch.cat((self.rhorad,self.rrsoc.unsqueeze(0)))\n",
    "        Ihat   = torch.matmul(torchA(Ms,rrFull).float(),self.Fs.float())\n",
    "        \n",
    "        return Ihat\n",
    "                \n",
    "    def computeLagrangeLossFactor(self) :\n",
    "        # Add in a fake Lagrange multiplier to discourage Fs < 0 and Fs > 1\n",
    "        oobsF = 1.0 * torch.sum((self.Fs < 0.0).float() * (self.Fs ** 2)) \n",
    "        oobsF = oobsF + 1.0 * torch.sum((self.Fs > 1.0).float() * (1.0 - self.Fs) **2)\n",
    "        \n",
    "        # Add in 1st derivative loss to smooth the curves\n",
    "        diffloss = torch.sum(torch.diff(self.Fs) ** 2)\n",
    "        diffloss += torch.sum(torch.diff(torch.diff(self.Fs)) ** 2)\n",
    "        \n",
    "        # Compute the loss function, which is chi-squared/NDF for spectra (1% SD) and msoc\n",
    "        # with a multiplicative factor for our fake Lagrange multipliers\n",
    "        return (1 + 100.0* diffloss + 1000.0*oobsF) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764ea3e-0e57-40fc-ac07-917989ec680c",
   "metadata": {},
   "source": [
    "### Load pre-trained encoder seed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e87e270-d42f-42de-927c-f5e487d28dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "(encoderModel,_,Is,seedFs,seedMs,rhorads,trueMSOC,dataInds,_,_) = torch.load(\"step6_fullFit_E20k_lr0p000005_b1_0p99_b2_0p999.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ff5dae-6f43-4b23-9b52-916a6bd8a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEndmembers = 90\n",
    "NPoints = Is.shape[0]\n",
    "MSpectra = 2151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adfe4811-4e54-4e01-90c2-bc1b013d5f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5905, 4987, 2252, ..., 8116,  933, 8757])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataInds.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60a5fc-4b90-4a56-bac9-ecf5665dba1d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b509a74-eca0-4d17-8d59-e50527f92cbd",
   "metadata": {},
   "source": [
    "Set up GPU training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09c2c0af-c810-4350-86b1-1f8071493bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch CUDA Version is  11.7\n",
      "Whether CUDA is supported by our system: True\n",
      "Name of the current CUDA Device:  NVIDIA GeForce RTX 4090\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Pytorch CUDA Version is \", torch.version.cuda)\n",
    "print(\"Whether CUDA is supported by our system:\", torch.cuda.is_available())\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(\"Name of the current CUDA Device: \", torch.cuda.get_device_name(cuda_id))\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c960eb91-dce0-4e14-9155-ea2fa3f7a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model seeds: Fs, Ms, and rhorads\n",
    "tFs      = torch.tensor(seedFs.tolist()).to(device)\n",
    "tMs      = torch.tensor(seedMs.tolist()).to(device)\n",
    "trhorads = torch.tensor(rhorads.tolist()).to(device)\n",
    "\n",
    "# Truth-level data:\n",
    "tmsoc    = torch.tensor(trueMSOC.tolist()).to(device)\n",
    "tIs      = torch.tensor(dataI[dataInds.astype('int')].tolist()).to(device)\n",
    "\n",
    "nepochs = 100000\n",
    "decoderModel = LinearMixingDecoder(tFs, tMs, trhorads).to(device)\n",
    "encoderDecoderParams = list(decoderModel.parameters()) + list(encoderModel.parameters())\n",
    "optimizer = optim.Adam(encoderDecoderParams, lr = 0.000005, betas=(0.99,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "931148d5-f8ce-4faf-b1f1-86acdbf2ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944360\n",
      "193591.0\n"
     ]
    }
   ],
   "source": [
    "encoderModelParams = filter(lambda p: p.requires_grad, encoderModel.parameters())\n",
    "numEncoderParams = sum([np.prod(p.size()) for p in encoderModelParams])\n",
    "print(numEncoderParams)\n",
    "\n",
    "decoderModelParams = filter(lambda p: p.requires_grad, decoderModel.parameters())\n",
    "numDecoderParams = sum([np.prod(p.size()) for p in decoderModelParams])\n",
    "print(numDecoderParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5204a9ec-9bdf-4ffe-88b7-3ef6802f2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer tracking\n",
    "cEpoch = 0\n",
    "lossTrackingEncoder = np.zeros(nepochs);\n",
    "lossTrackingDecoder = np.zeros(nepochs);\n",
    "lossTrackingDecoderLagrangeFactor = np.zeros(nepochs);\n",
    "\n",
    "encoderPreds=[]\n",
    "decoderPreds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35695d-4644-4b83-9eb2-7b9fe95721cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ea90f14ca6480fbda31b299bb91473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10315/2082774099.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ms = self.smax(y_mlp);\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(nepochs)) :\n",
    "    # Get abundance predictions from encoder\n",
    "    encoderPreds = encoderModel(tIs)\n",
    "    \n",
    "    # Get spectrum predictions from decoder\n",
    "    decoderPreds = decoderModel(encoderPreds)\n",
    "    \n",
    "    # Compute encoder loss: sqerr from true Msoc values\n",
    "    loss = 1000*torch.mean((encoderPreds[:,-1] - tmsoc)**2) \n",
    "    \n",
    "    lossTrackingEncoder[cEpoch] = loss.detach().item()\n",
    "    \n",
    "    # Add decoder loss: sqerr from true RaCA spectra\n",
    "    loss = loss + torch.mean((decoderPreds - tIs)**2) * decoderModel.computeLagrangeLossFactor()\n",
    "\n",
    "    lossTrackingDecoder[cEpoch] = loss.detach().item() - lossTrackingEncoder[cEpoch]\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    cEpoch += 1\n",
    "\n",
    "print(\"Epoch \",epoch,\": \", lossTrackingEncoder[-1]+lossTrackingDecoder[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71361d-4671-49cf-9011-7684191516dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axarr = plt.subplots(2,2,figsize=(10,10))\n",
    "\n",
    "axarr[0,0].scatter(trueMSOC[:],np.array(encoderPreds[:,-1].tolist()))\n",
    "axarr[0,0].set_xlabel(\"True SOC abundance\")\n",
    "axarr[0,0].set_ylabel(\"Encoder-predicted SOC abundance\")\n",
    "\n",
    "axarr[0,1].scatter([i for i in range(lossTrackingEncoder.shape[0])],lossTrackingEncoder)\n",
    "axarr[0,1].set_xlabel(\"Epoch\")\n",
    "axarr[0,1].set_ylabel(\"Encoder Loss\")\n",
    "\n",
    "axarr[1,0].scatter([i for i in range(lossTrackingDecoder.shape[0])],lossTrackingDecoder)\n",
    "axarr[1,0].set_xlabel(\"Epoch\")\n",
    "axarr[1,0].set_ylabel(\"Decoder Loss\")\n",
    "\n",
    "axarr[1,1].scatter([i for i in range(lossTrackingEncoder.shape[0])],lossTrackingEncoder+lossTrackingDecoder)\n",
    "axarr[1,1].set_xlabel(\"Epoch\")\n",
    "axarr[1,1].set_ylabel(\"Total Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7367cd8d-c772-4fd9-8219-53761b421438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "torch.save((encoderModel,decoderModel,optimizer,Is,seedFs,seedMs,rhorads,trueMSOC,dataInds,encoderPreds,decoderPreds,lossTrackingEncoder,lossTrackingDecoder), \"step8_fullFit_E20k_lr0p000005_b1_0p99_b2_0p999.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5b60d-013b-4ac8-9975-5144a10527c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
